# 前言、概览&简单的一元线性回归

## 前言

### 都5202年了怎么还有人在machine learning啊？？

虽然在大模型遍地跑，人和AI谈恋爱的时代，还在谈机器学习显得好像有点土(？)。但在事实上，机器学习思想是指导了几乎所有深度学习模型的提出与运用。如何结合概率论与数理统计、凸优化和算法理论让计算机实现对现有数据的学习的思想，是机器学习的精髓。

本系列的文章主要结合我在学习机器学习过程中的一些笔记、吴恩达老师在coursera的公开课和一些论文、网络资料完成。

## 概览

### 什么是机器学习？
机器学习(Machine Learning)融合了微积分、信息论、概率论与数理统计、凸优化等学科，上承统计学习与计算机科学，下衍生出现代深度学习的诸多算法。机器学习的目标可以近似用一句话概括：它研究的是如何让计算机通过经验自动改善性能。更正式地说：

**机器学习是对一类算法的研究，这些算法能够让计算机自动地从数据中学习规律，并利用这些规律对未知数据进行预测或决策**

假设你是一个篮球新手，正在学习投篮。第一次，你投出的球三不沾了，你明白：应该是力度小了。第二次，球打在篮板上飞了出去，你开始试着调整方向....经过多次调整，你终于找到了在当下位置将球送入篮筐的最佳力度和角度。

**这就是机器学习的核心思想：**

```
从反馈中调整模型，使它越来越“聪明”，最终从经验中学习到“自主判断”

```

### 机器学习的主要领域与任务分类

#### 根据是否有“答案”分类

机器学习可以大致分为 **监督学习(Supervised Learning)**和**无监督学习(Unsupervised Learning)** 两个领域。近年来也随之衍生出了半监督学习(Semi-supervised Learning)这样结合监督学习和无监督学习的方法，以及自监督学习(Self-supervised Learning)等新的算法，但这些在最近的篇幅中不会提到。

区分**监督学习**和**无监督学习**的核心依据是：

**算法是否拥有“标签”作为学习指导**

形式化地表达：

对于监督学习训练数据集，我们通常会有：

$$
\mathcal{D} = \{(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\}
$$

其中 $x_i$ 表示输入的特征，
$y_i$ 表示特征对应的标签。

更形象地说，在分类任务中，可能我们想通过鸟类的特征对鸟类进行分类。因此对于每张鸟类的照片我们可能会有以下特征:{黄色羽毛，中等体型，构型喙，长翅膀，脚部有蹼}，这就是数据点对应的特征 $x_i$。而鸟的种类为麻雀——这就是数据的标签
$y_i$ 。

监督学习的目标是通过已知的数据 $x_i$ 学习一个函数 $\mathcal{f}$ ,通过使用标签 
$y_i$ 使预期的输出 
$f(x_i)$ 能够逼近于
$y_i$
从而得到一个函数 $f(x)$ 对新的数据
$x$ 进行预测

而无监督学习的训练数据集只有 $\mathcal{D} = \{x_1, x_2, \dots, x_n\}$ 而没有标签
$y$。
数据集中每个样本只有输入特征，没有对应的输出标签。在无监督学习中我们只有 $x_i$ ，
即我们只有 $x_1$ = {黄色羽毛，中等体型，构型喙，长翅膀}，脚部有蹼，鸟鸣音高}而没有标签 $y_i$  
学习的目标是从数据中发现隐含的结构(黄色羽毛、中等体型的数据会聚在一起....等)

```
机器学习
├── 监督学习
├── 非监督学习
└── 强化学习

```

#### 根据目标分类

机器学习算法可以依据它们的 **学习目标（Learning Objective)** 进行系统分类。所谓“学习目标”，是指算法试图通过训练数据学会什么，并用于解决哪类问题。常见的学习目标包括：回归、分类、聚类、降维、异常检测等。

```

机器学习
├── 监督学习
│   ├── 分类任务
│   └── 回归任务
├── 非监督学习
│   ├── 聚类
│   └── 降维
└── 强化学习

```

##### 回归(regression)

目标：学习一个从输入到连续数值输出的映射
$f$

$f: \mathbb{R}^n \rightarrow \mathbb{R}$

给定数据集 $\mathcal{D}=\{(x_1,y_1),(x_2,y_2),...(x_n,y_n)\}$
目标是学习一个函数 $\mathcal{f}$，使得预测值 
$\mathcal{f}(x_i)$
与真实值 $y_i$ 尽可能接近

当你想要：

-根据面积、位置、楼层等特征，预测房屋售价

-根据作业分数、出勤率等因子，预测期末考试分数

-根据电动车的当前电量、速度、负载等，预测还能行驶的公里数

...

这些通过一系列输入映射到连续数值输出的任务，都可以通过构造一个回归算法来进行拟合

##### 分类(Classification)

分类是一个贯穿人类历史的任务。从动物、植物、果实是否能吃，一直到现代诸多分类学理论的兴起，甚至是哲学对分类的讨论，分类一直是人类认识世界的重要手段。在机器学习中，分类任务可以被定义为：

对于输入空间 $\mathbb{R}^n$,学习一个映射
$\mathcal{f}$
使得 $f: \mathbb{R}^n \rightarrow \mathbb{Z}^+$ which means
$\mathcal{f}(x)=\{1,2,...,K\}$

如果你想要对垃圾邮件进行识别(这意味着每封邮件都有两个可能的标签：垃圾邮件、非垃圾邮件)，医学诊断(阴性、阳性/良性、恶性)或图像识别，这时候构建一个分类器可以适当地解决问题

##### 聚类(Clustering)

当你拥有一大堆数据——但是没有标签。你可能想要通过一些算法来找到这些数据内在的模式和联系，如对客户进行分群，将新闻按主题分为“科技”、“体育”、“政治”等大类，又或是通过一系列基因型特征来发现基因表达与生物特征之间的联系。这时你可以合理地使用一些聚类算法。聚类算法是一类典型的无监督学习算法，目标是在没有标签的前提下，将数据划分为 $\mathcal{K}$ 个互不重叠的簇，使得同一簇内的样本尽可能相似。以经典的K-means算法为例。K-means算法的目标为：

$\min_{C_1, \dots, C_K} \sum_{k=1}^K \sum_{x_i \in C_k} \| x_i - \mu_k \|^2$

其中：

$\mathcal{C}_k$ :第K个簇

$\mu_k$ :该簇的中心

$\| x_i - \mu_k \|^2$ :欧式距离平方

K-means 是一种无监督聚类算法，其核心思想是：通过最小化样本点到其所属聚类中心的欧几里得距离的平方和，从而将数据划分为K个簇。该过程等价于 **最小化簇内方差(within-cluster variance)** 的无监督优化目标。

##### 降维(Dimensionality Reduction)

降维是一种在保持数据主要结构和信息的前提下，将高维数据投影到低维空间的过程。该过程常用于数据可视化、压缩、去噪和提高模型效率，是无监督学习中的核心任务之一。

假设有数据集 $\mathcal{D} = \{x_1, x_2, \dots, x_n\} \subset \mathbb{R}^d$

降维的目标是学习一个映射函数 $\mathcal{f}$

使得 $f: \mathbb{R}^d \to \mathbb{R}^k, \quad \text{其中 } k \ll d$

映射后的表示 $\mathcal{z}_i=\mathcal{f}(x_i)$ 尽可能保留原始数据的结构或变异性。

与聚类最小化方差的目标相对比，降维算法通常通过找到一个好的投影方法来使数据方差最大，以此来保证在降维后数据点依然能良好地分离。降维在减小模型规模，缓解维度灾难、可视化、去噪和压缩以及特征工程等应用中起到了重要作用。

## 1.简单的一元线性回归

假设我们是一名房东，正在考虑出售手上的一处房屋。信息时代的方便之处在于，我们可以参考其他房屋的出售情况来合理地制定房屋的出售价格。通过中介软件等渠道，我们得到了一系列房屋成交价格的数据。以一般的角度来思考，我们猜想房屋应该是越大越贵，因此我们可以尝试寻找房屋的面积与成交价格的规律。


![data table size price](img/data%20table%20size%20price.jpg)

在这里我们要接触到一个机器学习中至关重要的概念：**假设(Hypothesis)**

### 假设(Hypothesis)

在机器学习中，所谓的“假设”并不是指哲学意义上的推测或猜想，而是指我们用来近似目标函数的一个具体函数。换句话说：

**假设是模型在训练数据中学习到的映射函数，用于对未知数据做出预测。**

形式上，我们设目标函数为 $\mathcal{f}^*$
，它将输入 $x$ 映射到输出 
$y$ 。由于 
$\mathcal{f}^*$
 对我们来说是未知的，我们需要从一个函数集合中选取一个具体的函数，去逼近它，这个被选中的函数就是我们的“假设”。假设是我们用来逼近目标函数的数学函数，它决定了我们能“学到多复杂的规律”。
选择什么样的假设空间，是机器学习中最关键的建模步骤之一：它既决定了模型能学什么，也决定了模型学不好时会犯什么样的错。

#### 选择合理的假设

合理地选择假设函数是一个非常关键的步骤。一个合理的假设应该满足：

**1.表达能力(Expressiveness)**

假设空间必须足够强大，能够表示目标函数的复杂性。

如果我们选择了一个线性函数来对非线性的关系进行逼近，注定结果会陷入**欠拟合(Underfitting)**

**2.泛化能力(Generalization)**

如果构造的模型过于复杂，模型就容易学习数据集中的噪声，参数量过大容易造成泛化能力不足，导致**过拟合(Overfitting)**

深度神经网络、复杂树模型能够逼近任意函数，但是也更容易过度地拟合有限的数据，此时噪声非常容易影响模型的结构。

这两个目标之间的张力，就是经典的**偏差-方差权衡(Bias-Variance Tradeoff)**

在实际应用中，我们可以从任务类型出发来选择模型类别。例如：二分类问题常用Logistic回归，回归问题常用多项式回归等。同时，假设的选择不应脱离实际问题的背景，比如医疗诊断任务通常倾向于高解释性的模型，而复杂的图像分类模型则会使用效果更优但解释性更弱的深度神经网络。同时，我们可以并行试验多个假设模型并进行对比，使用交叉验证或控制复杂模型的复杂度来完成模型的假设。“合理的假设函数”是在数据复杂性、任务需求、模型能力与泛化表现之间寻求平衡的产物。

#### 构建模型

现在，我们不妨假设房屋价格与房屋的面积线性相关 **(别管为什么猜线性，来都来了先试试)**

因此我们可以得到房屋价格随面积线性变化的式子:

$\mathcal{f}_{w,b}(x)=wx+b$

我们可以给此处提到的字母一些新名字：

x:"input variable"，输入变量或"feature"，特征

y:"output variable"，输出变量或"target"，目标

w:"weight"，权重

b:"bias"，偏差

正好，我们已有的数据集可以被映射到一个二维坐标系中，我们试着得到一张图表：

![dots](./img/dots.jpg)

我们实际上就是在假设房屋的尺寸x与价格y是线性关系，也就是可以用一条直线来对数据点进行拟合，即我们可以尝试用不同的参数决定的直线来与数据进行“对齐”：

![dots with line](./img/dots%20with%20line.jpg)：

现在我们就完成了第一步：以合理的假设初步构建一个模型

**这就好像教练教会了我们投篮的基本动作。下一个问题是：我们该用多大的力度，向什么方向投篮才能命中篮筐呢？**

### 定义损失函数(目标函数)

在投篮的例子中，我们的每一次投篮都会得到一个反馈：我们投出的篮球距离篮筐多远，偏向左边或者右边。而我们的目标是将球恰好投进篮筐。而在房屋出售的例子中，我们的目标是以一个合理的价格出售房子——与相似面积的已售出房屋相比不太高也不太低。

具体在二维坐标系中，我们的目标是最小化预测值与真实数据的差，即：

$min\| \mathcal{f}(x_i)-y_i\|$

**：说了那么多，机器我是看到了，学习是体现在哪里**

那么我们如何让算法自己通过数据一步一步学习呢？

现在我们有了投篮的姿势，也知道了我们的目标——命中篮筐。剩下需要做的就是一个一个地投篮，并随着投出篮球的轨迹来调整我们的发力和角度。在房屋出售的例子中，我们有房屋的尺寸作为输入特征 $x_i$ ，
房屋出售的价格 $y_i$ 作为标签，那么我们就可以：

观察我们的模型在每个输入特征下得到的标签 $\mathcal{f}_(x_i)$ ,并通过考虑
$\|\mathcal{f}(x_i)-y_i\|$ 来对模型的参数进行调整，得到一个越来越接近真实分布的模型

此时对于数据 $(x^{(m)},y^{(m)})$，此处 $m$ 表示第 $m$ 组数据

我们进行：

$\| \mathcal{f}(x^{(m)})-y^{(m)}\|$

一个简单的方法是，我们将 $m$ 组预测值与真实数据的差值进行加和后取平均，即：

$$

J=\frac{1}{2m} \sum_{i=1}^{m}(f(x^{(i)})-y^{(i)})^2

$$

函数 $J$ 衡量了我们的假设与真实值之间的差距，也就是——投出的篮球距离命中的差距。而我们想要最小化这个差距，使篮球命中篮筐。一种一致的名称是，我们称这个函数为**代价函数或损失函数(cost function)**

*你可能会好奇为什么分母是 $2m$，
而后面求的是平方和而不是简单地计算误差的绝对值。别急，我们后面会提到，你就先记住(不是)

现在你可能觉得有两个参数 $w和b$ 的模型比较复杂，不够直观。为了更直观地理解这个问题，我们不妨设 $b=0$ ，也就是说，现在的模型是一条过二维平面原点的直线。

目前我们有：

模型 $f_w(x)=wx$

参数 $w$

损失函数 $J=\frac{1}{2m} \sum_{i=1}^{m}(f(x^{(i)})-y^{(i)})^2$

目标 $minimizeJ$

因此，我们得到的模型表示在二维直角坐标系上形如：


![f in axies](./img/f%20in%20axies.jpg)

随着参数w的变化，模型也会不同程度地拟合数据集：

![different w](./img/different%20w.jpg)

那么如何设计一个算法自动地根据拟合数据集的程度自动地改变参数，从而达成学习的目标呢？

### 选择优化方法

在前面我们提到了损失函数，即“衡量目前的拟合情况与真实值之间的差距”。一种较为自然的想法就是：计算每一个节点下模型拟合值与数据集标签的差距，令模型向减小差距的方向改变——简单地来说，如果w值过大，则让w适当减小；若w值过小，则令w适当增大。

我们可以结合模型 $f_w(x)$ 
和损失函数 $J(w)$ 在参数w取不同值的情况下来观察，表现在图像上就是：

![campare diff w](./img/campare%20diff%20w.jpg)

在右侧的图像中，我们将损失函数 $J$ 看作是关于参数 $w$ 的函数 $J(w)$。虽然损失的计算依赖于数据
$(x_i,y_i)$ ，但从模型训练的角度，我们关心的是：不同的参数
$w$ 会对模型在同一个数据集
$D={x_i,y_i}$ 上的表现产生多大影响？

从图像上我们可以清晰地看出，当模型取 $f_w(x)=wx$ 时，损失函数
$J(w)$ 关于 $w$ 的图像呈二次函数抛物线样——随着 $w$ 的取值趋近于1，损失函数 $J(w)$ 趋近于最小值0

也就是：

$\lim_{w \to 1}J(w)=0$

目标我们的优化过程可以抽象为：在损失函数 $J(w)$ 所构成的参数空间中，寻找参数值 $w^*$ 使 $J(w)$ 最小 

寻找最小值在简单的模型(如我们现在所假设的线性模型 $f(x)=wx$ 中)可以简单地通过矩阵乘法等方式数值求解。但在参数量较大，假设较复杂的模型中，数值求解较为困难，我们现在介绍一种适用于绝大部分模型的方法：**梯度下降(Gradient Decent)**

可以用一个形象的比喻对梯度下降进行一个类比：想象你站在一座山上，你住在山脚，而现在到了吃饭的时间。你的目标就是尽可能快地走到山脚下的家里。这时你需要做的是：从山上的某一点出发，沿着**最陡峭的方向**，**一步步**地走向山的最低点

我们将下山的过程进一步地分解，你需要：

1.环顾四周，寻找一个最陡峭的下山方向——这个方向同时由横向的坡度和纵向的坡度决定

2.以一个步长沿着这个方向下降一段距离

3.继续寻找下一个方向

#### 当我们在谈论“陡峭”的时候，我们在谈论什么？

如何来衡量“最陡峭”到底有多陡峭呢？可以形象地比喻：陡峭实际上是在讨论在某点上向某个方向变化的快慢程度。这里我们不得不进行一些数学形式上的引入

将损失函数 $J(w)$ 看作一个定义在参数空间上的实值函数：

$$
J: \mathbb{R}^n \rightarrow \mathbb{R}, \quad w \mapsto J(w)
$$

数学上计算方程在一点上的“梯度”——方程在不同方向上变化的速度，即“陡峭程度”

$\nabla J(w)=\frac{\partial}{\partial w}J(w)$

简化到一元方程中，我们会发现“梯度”就是我们初高中学过的“导数”，也就是斜率：

$\nabla J(w_0)=\frac{d}{dw}J(w)_{|w=w_0}$

#### 梯度下降(Gradient Decent)

我们设步长为 $\eta$ ，则我们走出的一步为：

$\eta\cdot\nabla J(\theta)$

我们对这一步骤进行不断的循环重复，直至损失函数下降到最低点(即收敛)，也就是：

$do:$

$w := w - \eta \cdot \nabla J(w)$

$repeat\quad until\quad convergence$

![grd in 2 dim](./img/grd%20in%202%20dim.jpg)

相同地，可以扩展至更高维：

![0b0d201a08a2212f681c5dfd7d3392ce](./img/0b0d201a08a2212f681c5dfd7d3392ce.jpg)

这里你可能注意到了：我们设置的步长 $\eta$ 决定了每一次更新参数时迈出多大的一步。因此讨论步长的选择是至关重要的

#### 学习率(Learning Rate)

步长(或更规范地称之为学习率)，是梯度下降中一个非常关键的超参数，选择合适的步长是决定模型训练效果的关键之一。将梯度下降的范围局限到一个小土坑，这时我们会发现：

1.如果你只是很谨慎地一点一点往下蹭，虽然可以安全且不迷路地滑落到低点，但是到底(收敛)的速度会非常慢

2.如果你一步三个台阶，你可能一脚直接踩到坑的对面，甚至“飞跃”更高点

只有合适的步伐大小才能在保证速度的基础上顺利地下到最低点。

![compare diff eta](./img/compare%20diff%20eta.jpg)

当 $\eta$ 选取过小时，模型收敛的速度较慢，且收敛时间长。而当 $\eta$ 选择的值过大，则很有可能剧烈震荡，甚至发散。

选取一个合适的学习率有很多方法；也有许多进阶的优化方法，诸如Adam、AdaGrad等自适应方法能够在训练的过程中动态地调整每个参数地学习率，此处暂时不表。

现在通过引入梯度下降的方法，我们成功地让计算机仿照人类学习投篮的过程自行对问题进行优化求解，通过以上过程我们现在有：

模型： $f_w(x)=wx$

参数： $w$

损失函数： $J=\frac{1}{2m} \sum_{i=1}^{m}(f(x^{(i)})-y^{(i)})^2$

目标： $minimizeJ$

梯度下降：

$do:$

$w := w - \eta \cdot \nabla J(w)$

$repeat\quad until\quad convergence$

这就是机器学习中最基础的一个模型：一元线性回归模型

在下一篇中，我们将会将一元线性模型扩展到更高的维度、并使用矩阵法对线性模型求解。同时，特征分布的不同会对模型的拟合产生不同的影响，我们会讨论到机器学习一个非常重要的组成部分：特征工程(Feature Engineering)。我们还会以线性模型为例探讨如何选择合适的超参数，以及观察模型拟合情况的方法。最后，我们会引入一个新的模型：多项式回归模型(Polynomial Regression)。

本篇参考吴恩达老师在Standford University的课程、网络资料以及本人的学习笔记而整理。

## 参考文献

[1]BohrXD，https://github.com/BohrXD/dumb-machine-learning


[2]Andrew Ng,coursera,https://www.deeplearning.ai/courses/machine-learning-specialization
